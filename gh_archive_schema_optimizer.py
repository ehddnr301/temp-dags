import os
import sys
import pandas as pd
import json
import ast
import re
from deltalake import DeltaTable, write_deltalake
from datetime import datetime
import pyarrow as pa
import pyarrow.compute as pc

def to_snake_case(name):
    """CamelCaseë¥¼ snake_caseë¡œ ë³€í™˜"""
    # CausalInferenceLab -> causal_inference_lab
    # Pseudo-Lab -> pseudo_lab
    s1 = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    s2 = re.sub('([a-z0-9])([A-Z])', r'\1_\2', s1).lower()
    s3 = s2.replace('-', '_')
    return s3

def convert_data_types(date_str):
    """
    CausalInferenceLab, Pseudo-Lab ë°ì´í„°ì˜ ì»¬ëŸ¼ íƒ€ì…ì„ ì ì ˆíˆ ë³€í™˜
    JSON ë¬¸ìì—´ë¡œ ì €ì¥ëœ nested ì»¬ëŸ¼ë“¤ì„ struct íƒ€ì…ìœ¼ë¡œ ë³µì›
    """
    # MinIO í™˜ê²½ ì„¤ì •
    os.environ["AWS_ACCESS_KEY_ID"] = "minioadmin"
    os.environ["AWS_SECRET_ACCESS_KEY"] = "minioadmin"
    os.environ["AWS_ENDPOINT_URL"] = "http://localhost:30090"
    os.environ["AWS_ALLOW_HTTP"] = "true"
    
    storage_options = {
        "AWS_ENDPOINT_URL": "http://localhost:30090",
        "AWS_ACCESS_KEY_ID": "minioadmin",
        "AWS_SECRET_ACCESS_KEY": "minioadmin",
        "AWS_REGION": "us-east-1",
        "AWS_ALLOW_HTTP": "true",
        "AWS_S3_ALLOW_UNSAFE_RENAME": "true"
    }
    
    target_logins = ["CausalInferenceLab", "Pseudo-Lab"]
    
    def safe_json_parse(json_str):
        """JSON ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±"""
        if pd.isna(json_str) or json_str is None or json_str == "" or json_str == "None":
            return None
        if isinstance(json_str, str):
            try:
                # ë¨¼ì € ast.literal_eval ì‹œë„ (single quote JSON)
                if json_str.strip().startswith('{'):
                    return ast.literal_eval(json_str)
                # ê·¸ ë‹¤ìŒ json.loads ì‹œë„ (double quote JSON)
                return json.loads(json_str)
            except:
                return None
        return json_str
    
    def create_struct_from_dict_list(dict_list, struct_name):
        """ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ì—ì„œ Arrow struct íƒ€ì…ì„ ìƒì„±"""
        if not dict_list or all(d is None for d in dict_list):
            # ëª¨ë“  ê°’ì´ Noneì´ë©´ null ì»¬ëŸ¼ ë°˜í™˜
            return pa.array([None] * len(dict_list))
        
        # Noneì´ ì•„ë‹Œ ì²« ë²ˆì§¸ ë”•ì…”ë„ˆë¦¬ì—ì„œ ìŠ¤í‚¤ë§ˆ ì¶”ì¶œ
        sample_dict = next((d for d in dict_list if d is not None), None)
        if sample_dict is None:
            return pa.array([None] * len(dict_list))
        
        # ìŠ¤í‚¤ë§ˆ ì •ì˜ (GitHub Archive í‘œì¤€ ìŠ¤í‚¤ë§ˆ)
        if struct_name == 'actor':
            schema = pa.struct([
                ('id', pa.int64()),
                ('login', pa.string()),
                ('display_login', pa.string()),
                ('gravatar_id', pa.string()),
                ('url', pa.string()),
                ('avatar_url', pa.string())
            ])
        elif struct_name == 'repo':
            schema = pa.struct([
                ('id', pa.int64()),
                ('name', pa.string()),
                ('url', pa.string())
            ])
        elif struct_name == 'org':
            schema = pa.struct([
                ('id', pa.int64()),
                ('login', pa.string()),
                ('gravatar_id', pa.string()),
                ('url', pa.string()),
                ('avatar_url', pa.string())
            ])
        else:  # payloadëŠ” ë™ì ìœ¼ë¡œ ì²˜ë¦¬
            # ìƒ˜í”Œì—ì„œ í•„ë“œ ì¶”ì¶œ
            fields = []
            for key, value in sample_dict.items():
                if isinstance(value, int):
                    fields.append((key, pa.int64()))
                elif isinstance(value, bool):
                    fields.append((key, pa.bool_()))
                elif isinstance(value, list):
                    fields.append((key, pa.string()))  # ë¦¬ìŠ¤íŠ¸ëŠ” JSON ë¬¸ìì—´ë¡œ
                else:
                    fields.append((key, pa.string()))
            schema = pa.struct(fields)
        
        # ë”•ì…”ë„ˆë¦¬ë¥¼ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜
        struct_data = []
        for d in dict_list:
            if d is None:
                struct_data.append(None)
            else:
                # ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ê°’ ë³€í™˜
                converted = {}
                for field in schema:
                    field_name = field.name
                    field_type = field.type
                    value = d.get(field_name)
                    
                    if value is None:
                        converted[field_name] = None
                    elif pa.types.is_integer(field_type):
                        try:
                            converted[field_name] = int(value) if value != "" else None
                        except:
                            converted[field_name] = None
                    elif pa.types.is_boolean(field_type):
                        converted[field_name] = bool(value) if value != "" else None
                    else:  # string
                        converted[field_name] = str(value) if value != "" else None
                
                struct_data.append(converted)
        
        return pa.array(struct_data, type=schema)
    
    def convert_dtypes_arrow(arrow_table):
        """Arrow í…Œì´ë¸”ì˜ íƒ€ì… ë³€í™˜"""
        columns = {}
        
        for field in arrow_table.schema:
            col_name = field.name
            col_data = arrow_table.column(col_name)
            
            # index level ì»¬ëŸ¼ ì œê±°
            if col_name.startswith("__index_level"):
                continue
                
            # boolean íƒ€ì… ë³€í™˜
            if col_name == 'public':
                try:
                    if pa.types.is_string(field.type):
                        bool_col = pc.equal(col_data, pa.scalar("True"))
                        columns[col_name] = bool_col
                    else:
                        columns[col_name] = col_data
                except Exception:
                    columns[col_name] = col_data
            
            # datetime íƒ€ì… ë³€í™˜
            elif col_name == 'created_at':
                try:
                    if pa.types.is_string(field.type):
                        timestamp_col = pc.strptime(col_data, format='%Y-%m-%dT%H:%M:%SZ', unit='s')
                        columns[col_name] = timestamp_col
                    else:
                        columns[col_name] = col_data
                except Exception:
                    columns[col_name] = col_data
            
            # payloadì™€ orgëŠ” JSON ë¬¸ìì—´ë¡œ ìœ ì§€ (ìŠ¤í‚¤ë§ˆ ë³€ë™ì„±ì´ í¼)
            elif col_name in ['payload', 'org']:
                # JSON ë¬¸ìì—´ ê·¸ëŒ€ë¡œ ìœ ì§€
                columns[col_name] = col_data
            
            # ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì •ì ì¸ êµ¬ì¡°ë§Œ structë¡œ ë³€í™˜
            elif col_name in ['actor', 'repo']:
                try:
                    # pandasë¡œ ë³€í™˜í•´ì„œ JSON íŒŒì‹±
                    pandas_col = col_data.to_pandas()
                    dict_list = [safe_json_parse(x) for x in pandas_col]
                    struct_col = create_struct_from_dict_list(dict_list, col_name)
                    columns[col_name] = struct_col
                except Exception as e:
                    print(f"âš ï¸ {col_name} struct ë³€í™˜ ì‹¤íŒ¨: {e}")
                    columns[col_name] = col_data
            
            # ë‹¤ë¥¸ ì»¬ëŸ¼ë“¤
            else:
                if pa.types.is_null(field.type):
                    null_col = pa.array([None] * len(col_data), type=pa.string())
                    columns[col_name] = null_col
                else:
                    columns[col_name] = col_data
        
        return pa.table(columns)
    
    print(f"ğŸ“… ì²˜ë¦¬ ì¼ì: {date_str}")
    
    for login in target_logins:
        try:
            # ë°ì´í„° ì½ê¸° (Arrow í…Œì´ë¸”ë¡œ ì§ì ‘ ì½ê¸°)
            source_path = f"s3://gh-archive-delta/dl_org_{login}_gh_archive/{date_str}/"
            print(f"ğŸ“‚ ì½ëŠ” ì¤‘: {source_path}")
            
            dt = DeltaTable(source_path)
            arrow_table = dt.to_pyarrow_table()
            print(f"ğŸ“Š {login} ì›ë³¸ ë°ì´í„°: {len(arrow_table)} í–‰")
            print(f"ğŸ“‹ ì›ë³¸ ìŠ¤í‚¤ë§ˆ:")
            for field in arrow_table.schema:
                print(f"   {field.name}: {field.type}")
            
            # íƒ€ì… ë³€í™˜
            arrow_table_converted = convert_dtypes_arrow(arrow_table)
            print(f"ğŸ“‹ ë³€í™˜ëœ ìŠ¤í‚¤ë§ˆ:")
            for field in arrow_table_converted.schema:
                print(f"   {field.name}: {field.type}")
            
            # base_date ì»¬ëŸ¼ ì¶”ê°€ (íŒŒí‹°ì…˜ìš© ë° ë©±ë“±ì„± ë³´ì¥)
            base_date_col = pa.array([date_str] * len(arrow_table_converted), type=pa.string())
            arrow_table_with_date = arrow_table_converted.append_column('base_date', base_date_col)
            
            # ì €ì¥ ê²½ë¡œ (í†µí•©ëœ í…Œì´ë¸”, snake_case ì²˜ë¦¬)
            login_snake = to_snake_case(login)
            output_path = f"s3://gh-archive-delta/dl_org_{login_snake}/"
            
            # í…Œì´ë¸”ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            try:
                existing_table = DeltaTable(output_path, storage_options=storage_options)
                table_exists = True
                print(f"ğŸ“‹ ê¸°ì¡´ í…Œì´ë¸” ë°œê²¬: {output_path}")
            except Exception:
                table_exists = False
                print(f"ğŸ“‹ ìƒˆ í…Œì´ë¸” ìƒì„±: {output_path}")
            
            if table_exists:
                # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ë‚ ì§œ íŒŒí‹°ì…˜ ì‚­ì œ í›„ ì¶”ê°€ (ë©±ë“±ì„± ë³´ì¥)
                print(f"ğŸ”„ {date_str} íŒŒí‹°ì…˜ ë°ì´í„° êµì²´ ì¤‘...")
                
                # í•´ë‹¹ ë‚ ì§œ íŒŒí‹°ì…˜ ì‚­ì œ (base_date ê¸°ì¤€)
                existing_table.delete(f"base_date = '{date_str}'")
                
                # ìƒˆ ë°ì´í„° ì¶”ê°€ (ìŠ¤í‚¤ë§ˆ ì§„í™” í—ˆìš©)
                write_deltalake(
                    output_path, 
                    arrow_table_with_date, 
                    mode="append", 
                    storage_options=storage_options,
                    partition_by=["base_date"],
                    schema_mode="merge"  # ìŠ¤í‚¤ë§ˆ ì§„í™” í—ˆìš©
                )
            else:
                # ì²« ë²ˆì§¸ ì‹¤í–‰ - í…Œì´ë¸” ìƒì„±
                write_deltalake(
                    output_path, 
                    arrow_table_with_date, 
                    mode="overwrite", 
                    storage_options=storage_options,
                    partition_by=["base_date"]
                )
            print(f"âœ… {login}: íƒ€ì… ë³€í™˜ ì™„ë£Œ â†’ {output_path}")
            
        except Exception as e:
            print(f"âŒ {login} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            import traceback
            print(f"   ì „ì²´ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
            continue

def validate_date(date_str):
    """ë‚ ì§œ í˜•ì‹ ê²€ì¦"""
    try:
        datetime.strptime(date_str, '%Y-%m-%d')
        return True
    except ValueError:
        return False

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("ì‚¬ìš©ë²•: python convert_data_types.py YYYY-MM-DD")
        print("ì˜ˆì‹œ: python convert_data_types.py 2025-01-01")
        sys.exit(1)
    
    date_param = sys.argv[1]
    
    if not validate_date(date_param):
        print("âŒ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹ì…ë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        sys.exit(1)
    
    convert_data_types(date_param) 