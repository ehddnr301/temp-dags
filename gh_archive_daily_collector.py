import os
import pandas as pd
import requests
import json
import gzip
import io
from datetime import datetime, timedelta
from deltalake import write_deltalake
import time
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def gharchive_url_for_hour(date_str: str, hour: int) -> str:
    """
    ì£¼ì–´ì§„ ë‚ ì§œ(date_str)ì™€ ì‹œê°„(hour)ì— í•´ë‹¹í•˜ëŠ” GH Archive URLì„ ë°˜í™˜.
    ex) 2025-07-12, 0ì‹œ -> "http://data.gharchive.org/2025-07-12-0.json.gz"
    """
    return f"http://data.gharchive.org/{date_str}-{hour}.json.gz"

def generate_urls_for_date(date_str: str) -> list[str]:
    """ë‚ ì§œ date_strì— ëŒ€í•œ 0ì‹œë¶€í„° 23ì‹œê¹Œì§€ 24ê°œì˜ URL ëª©ë¡ì„ ìƒì„±."""
    return [gharchive_url_for_hour(date_str, h) for h in range(24)]

def download_data(url: str) -> bytes:
    """ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    response = requests.get(url, timeout=30)
    response.raise_for_status()
    return response.content

def unzip_data(compressed_data: bytes) -> list[dict]:
    """ì••ì¶• í•´ì œ ë° JSON íŒŒì‹±"""
    events = []
    with gzip.GzipFile(fileobj=io.BytesIO(compressed_data)) as f:
        for line in f:
            try:
                event = json.loads(line.decode('utf-8'))
                if isinstance(event, dict):
                    events.append(event)
            except json.JSONDecodeError:
                continue
    return events

def save_to_delta(events: list[dict], date: str, organization: str):
    """ë¸íƒ€ í…Œì´ë¸”ì— ì €ì¥"""
    if not events:
        logger.warning(f"âš ï¸ {date} - ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return
    
    df = pd.DataFrame(events)
    df['date'] = date
    df['created_at'] = pd.to_datetime(df['created_at'])
    
    delta_path = f"s3://gh-archive/gh-archive-{organization.lower()}"
    partition_path = f"{delta_path}/date={date}"
    
    write_deltalake(partition_path, df, mode="overwrite", partition_by=["date"])
    logger.info(f"ğŸ’¾ {date} - {len(df)}ê°œ ì´ë²¤íŠ¸ ì €ì¥ ì™„ë£Œ")

def download_all_data(date: str) -> list[dict]:
    """íŠ¹ì • ë‚ ì§œì˜ ëª¨ë“  ë°ì´í„° ë‹¤ìš´ë¡œë“œ"""
    all_events = []
    
    for url in generate_urls_for_date(date):
        try:
            compressed_data = download_data(url)
            events = unzip_data(compressed_data)
            all_events.extend(events)
            time.sleep(0.1)  # ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
        except Exception as e:
            logger.error(f"âŒ {url} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    
    logger.info(f"ğŸ“Š {date} - ì´ {len(all_events)}ê°œ ì´ë²¤íŠ¸ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
    return all_events

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    
    if len(sys.argv) != 4:
        print("ì‚¬ìš©ë²•: python gh_archive_daily_collector.py <YYYY-MM-DD> <organization> <func_type>")
        print("func_type ì˜µì…˜:")
        print("  - download: ë°ì´í„° ë‹¤ìš´ë¡œë“œë§Œ")
        print("  - unzip: ì••ì¶• í•´ì œë§Œ")
        print("  - save: ë¸íƒ€ í…Œì´ë¸” ì €ì¥ë§Œ")
        print("  - all: ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰")
        sys.exit(1)
    
    date = sys.argv[1]
    organization = sys.argv[2]
    func_type = sys.argv[3]
    
    try:
        datetime.strptime(date, '%Y-%m-%d')
    except ValueError:
        logger.error(f"âŒ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {date}")
        sys.exit(1)
    
    logger.info(f"ğŸš€ {date} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ - í•¨ìˆ˜ íƒ€ì…: {func_type}")
    
    if func_type == "download":
        # ë°ì´í„° ë‹¤ìš´ë¡œë“œë§Œ
        events = download_all_data(date)
        logger.info(f"âœ… {date} ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ - {len(events)}ê°œ ì´ë²¤íŠ¸")
        
    elif func_type == "unzip":
        # ì••ì¶• í•´ì œë§Œ (ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ê°€ ìˆë‹¤ê³  ê°€ì •)
        logger.info(f"ğŸ“¦ {date} ì••ì¶• í•´ì œ ì‘ì—… ì‹œì‘")
        # ì‹¤ì œë¡œëŠ” ë‹¤ìš´ë¡œë“œëœ ë°ì´í„°ë¥¼ ë‹¤ì‹œ ì••ì¶• í•´ì œí•˜ëŠ” ê²ƒì´ë¯€ë¡œ
        # ì—¬ê¸°ì„œëŠ” ë‹¤ìš´ë¡œë“œì™€ ì••ì¶• í•´ì œë¥¼ í•¨ê»˜ ìˆ˜í–‰
        events = download_all_data(date)
        logger.info(f"âœ… {date} ì••ì¶• í•´ì œ ì™„ë£Œ - {len(events)}ê°œ ì´ë²¤íŠ¸")
        
    elif func_type == "save":
        # ë¸íƒ€ í…Œì´ë¸” ì €ì¥ë§Œ (ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ìˆë‹¤ê³  ê°€ì •)
        logger.info(f"ğŸ’¾ {date} ë¸íƒ€ í…Œì´ë¸” ì €ì¥ ì‘ì—… ì‹œì‘")
        # ì‹¤ì œë¡œëŠ” ì´ì „ ë‹¨ê³„ì—ì„œ ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ì§€ë§Œ
        # ì—¬ê¸°ì„œëŠ” ì „ì²´ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰
        events = download_all_data(date)
        save_to_delta(events, date, organization)
        logger.info(f"âœ… {date} ë¸íƒ€ í…Œì´ë¸” ì €ì¥ ì™„ë£Œ")
        
    elif func_type == "all":
        # ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        events = download_all_data(date)
        save_to_delta(events, date, organization)
        logger.info(f"âœ… {date} ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
        
    else:
        logger.error(f"âŒ ì˜ëª»ëœ í•¨ìˆ˜ íƒ€ì…: {func_type}")
        print("ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ íƒ€ì…: download, unzip, save, all")
        sys.exit(1)

if __name__ == "__main__":
    main()
