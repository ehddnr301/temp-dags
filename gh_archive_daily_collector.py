import os
import pandas as pd
import requests
import json
from datetime import datetime, timedelta
from deltalake import write_deltalake
import time
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# MinIO í™˜ê²½ ë³€ìˆ˜
os.environ["AWS_ACCESS_KEY_ID"] = "minioadmin"
os.environ["AWS_SECRET_ACCESS_KEY"] = "minioadmin"
os.environ["AWS_ENDPOINT_URL"] = "http://minio:9000"
os.environ["AWS_ALLOW_HTTP"] = "true"
os.environ["AWS_CONDITIONAL_PUT"] = "etag"

def fetch_organization_data(date: str, organization: str) -> pd.DataFrame:
    """íŠ¹ì • ë‚ ì§œì™€ organizationì˜ GH Archive ë°ì´í„° ìˆ˜ì§‘"""
    base_url = "https://data.gharchive.org"
    all_events = []
    
    for hour in range(24):
        url = f"{base_url}/{date}-{hour}.json.gz"
        try:
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            for line in response.text.strip().split('\n'):
                if line:
                    try:
                        event = json.loads(line)
                        # organization ê´€ë ¨ ì´ë²¤íŠ¸ë§Œ í•„í„°ë§
                        if (event.get('repo', {}).get('name', '').startswith(f"{organization}/") or
                            event.get('org', {}).get('login') == organization):
                            all_events.append(event)
                    except json.JSONDecodeError:
                        continue
            
            time.sleep(0.1)  # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
            
        except requests.RequestException as e:
            logger.error(f"âŒ {date} {hour:02d}:00 ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    if not all_events:
        return pd.DataFrame()
    
    df = pd.DataFrame(all_events)
    df['date'] = date
    df['created_at'] = pd.to_datetime(df['created_at'])
    
    logger.info(f"ğŸ“Š {date} - {len(df)}ê°œ ì´ë²¤íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ")
    return df

def write_to_delta(df: pd.DataFrame, date: str, organization: str):
    """ë¸íƒ€ í…Œì´ë¸”ì— ë°ì´í„° ì“°ê¸°"""
    if df.empty:
        logger.warning(f"âš ï¸ {date} - ë¹ˆ ë°ì´í„°")
        return
    
    try:
        delta_path = f"s3://gh-archive/gh-archive-{organization.lower()}"
        partition_path = f"{delta_path}/date={date}"
        
        write_deltalake(partition_path, df, mode="overwrite", partition_by=["date"])
        logger.info(f"ğŸ’¾ {date} ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ {date} ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import sys
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ ì²˜ë¦¬
    if len(sys.argv) != 3:
        print("ì‚¬ìš©ë²•: python gh_archive_daily_collector.py <YYYY-MM-DD> <organization>")
        print("ì˜ˆì‹œ: python gh_archive_daily_collector.py 2024-01-15 apache")
        sys.exit(1)
    
    date = sys.argv[1]
    organization = sys.argv[2]
    
    # ë‚ ì§œ í˜•ì‹ ê²€ì¦
    try:
        datetime.strptime(date, '%Y-%m-%d')
    except ValueError:
        logger.error(f"âŒ ì˜ëª»ëœ ë‚ ì§œ í˜•ì‹: {date}. YYYY-MM-DD í˜•ì‹ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
        sys.exit(1)
    
    logger.info(f"ğŸš€ {date} {organization} ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    
    # ë°ì´í„° ìˆ˜ì§‘
    df = fetch_organization_data(date, organization)
    
    # ë¸íƒ€ í…Œì´ë¸”ì— ì €ì¥
    write_to_delta(df, date, organization)
    
    logger.info(f"âœ… {date} {organization} ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ")

if __name__ == "__main__":
    main()
